{"cells":[{"cell_type":"code","source":["%pip install azure-cognitiveservices-speech"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6042c33d-d831-4da4-890d-da2fb8e3d3c8"},{"cell_type":"code","source":["key_vault_name = 'ckmv2-keyvault' #'kv_to-be-replaced'"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"46b5e38d-0232-4336-9d64-0c0a3687efed"},{"cell_type":"code","source":["from trident_token_library_wrapper import PyTridentTokenLibrary as tl\n","\n","def get_secrets_from_kv(kv_name, secret_name):\n","\n","    access_token = mssparkutils.credentials.getToken(\"keyvault\")\n","    kv_endpoint = f'https://{kv_name}.vault.azure.net/'\n","    return(tl.get_secret_with_token(kv_endpoint,secret_name,access_token))\n","\n","openai_api_type = \"azure\"\n","openai_api_version  = get_secrets_from_kv(key_vault_name,\"AZURE-OPENAI-VERSION\")\n","openai_api_base = get_secrets_from_kv(key_vault_name,\"AZURE-OPENAI-ENDPOINT\")\n","openai_api_key = get_secrets_from_kv(key_vault_name,\"AZURE-OPENAI-KEY\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"34455249-5154-4cf8-b102-abcef9ca9d89"},{"cell_type":"code","source":["#Set AI services variables\n","ai_services_endpoint = get_secrets_from_kv(key_vault_name,\"COG-SERVICES-ENDPOINT\") \n","ai_services_key = get_secrets_from_kv(key_vault_name,\"COG-SERVICES-KEY\") \n","ai_services_region = 'eastus' #get_secrets_from_kv(key_vault_name,\"AZURE-LOCATION\")\n","# wav_file_path = '/lakehouse/default/Files/data/audio_input/Travel_20240124183556.wav'\n","language1 = 'en-US'"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"d029f378-0e5a-41c9-aac6-81abeb63355e","statement_id":9,"statement_ids":[9],"state":"finished","livy_statement_state":"available","queued_time":"2024-05-07T21:57:01.5671749Z","session_start_time":null,"execution_start_time":"2024-05-07T21:57:06.6621583Z","execution_finish_time":"2024-05-07T21:57:06.9184035Z","parent_msg_id":"7dd2128b-c12b-4bfd-9568-c0dd8d11958b"},"text/plain":"StatementMeta(, d029f378-0e5a-41c9-aac6-81abeb63355e, 9, Finished, Available)"},"metadata":{}}],"execution_count":2,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e4d20f3e-8425-4ed7-add7-2056418afdb9"},{"cell_type":"code","source":["#Drop the metadata table if it already exists\n","spark.sql('drop table if exists ckm_lakehouse.ckm_conv_metadata')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"d029f378-0e5a-41c9-aac6-81abeb63355e","statement_id":10,"statement_ids":[10],"state":"finished","livy_statement_state":"available","queued_time":"2024-05-07T21:57:13.0794052Z","session_start_time":null,"execution_start_time":"2024-05-07T21:57:13.6011235Z","execution_finish_time":"2024-05-07T21:57:30.7368152Z","parent_msg_id":"77cad422-2ffa-4924-9f6f-f265b27260e1"},"text/plain":"StatementMeta(, d029f378-0e5a-41c9-aac6-81abeb63355e, 10, Finished, Available)"},"metadata":{}},{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"DataFrame[]"},"metadata":{}}],"execution_count":3,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"be8cacd3-e46b-49dd-a13a-1f85477dda39"},{"cell_type":"code","source":["from pyspark.sql import functions as F\n","\n","spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")\n","\n","# Read all the CSV files in the directory\n","df = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"Files/data/audio_input/*.csv\")\n","\n","# Convert StartTime and EndTime to timestamp format\n","df = df.withColumn(\"StartTime\", F.to_timestamp(\"StartTime\", \"MM/dd/yyyy h:mm:ss a\"))\n","df = df.withColumn(\"EndTime\", F.to_timestamp(\"EndTime\", \"MM/dd/yyyy h:mm:ss a\"))\n","\n","# Calculate the duration in milliseconds and add it as a new column\n","df = df.withColumn(\"Duration\", (F.col(\"EndTime\").cast(\"long\") - F.col(\"StartTime\").cast(\"long\")) / 60)\n","\n","\n","# Write the DataFrame to a Delta table\n","df.write.format('delta').mode('overwrite').option(\"overwriteSchema\", \"true\").saveAsTable('ckm_conv_metadata')\n","\n","# # Display the first 2 rows\n","# display(df.head(2))\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false,"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"55e3c4a2-e888-4bd8-add1-fb08f42af75c"},{"cell_type":"code","source":["# df = spark.sql(\"SELECT * FROM ckm_lakehouse.ckm_conv_metadata LIMIT 1000\")\n","# display(df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false,"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8015c4ec-99c9-44be-a7af-50ef8a941793"},{"cell_type":"code","source":["#https://learn.microsoft.com/en-us/azure/ai-services/speech-service/get-started-stt-diarization?tabs=windows&pivots=programming-language-python\n","import os\n","import time\n","import azure.cognitiveservices.speech as speechsdk\n","import json\n","\n","def transcribe_from_file(ai_services_key,ai_services_region,wav_file_path, conversation_id):\n","    all_results = list()\n","\n","    speech_config = speechsdk.SpeechConfig(subscription=ai_services_key, region=ai_services_region)\n","    speech_config.speech_recognition_language=\"en-US\"\n","\n","    audio_config = speechsdk.audio.AudioConfig(filename=wav_file_path)\n","    conversation_transcriber = speechsdk.transcription.ConversationTranscriber(speech_config=speech_config, audio_config=audio_config)\n","\n","    transcribing_stop = False\n","\n","    def conversation_transcriber_session_started_cb(evt: speechsdk.SessionEventArgs):\n","        pass \n","        # print('SessionStarted event')\n","\n","    def stop_cb(evt: speechsdk.SessionEventArgs): #callback that signals to stop continuous recognition upon receiving an event `evt`\n","        nonlocal transcribing_stop\n","        transcribing_stop = True\n","\n","    def conversation_transcriber_recognition_canceled_cb(evt: speechsdk.SessionEventArgs):\n","        pass\n","        # print('Canceled event')\n","\n","    def conversation_transcriber_session_stopped_cb(evt: speechsdk.SessionEventArgs):\n","        pass\n","        # print('SessionStopped event')\n","\n","    def handle_final_result(evt):\n","        nonlocal all_results\n","        if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech:\n","            #https://learn.microsoft.com/en-us/python/api/azure-cognitiveservices-speech/azure.cognitiveservices.speech.recognitionresult?view=azure-python\n","            r = json.loads(evt.result.json)\n","            all_results.append([conversation_id,\n","                                r[\"Id\"],\n","                                r[\"DisplayText\"],\n","                                r[\"Offset\"],\n","                                r[\"Duration\"],\n","                                r[\"Channel\"],\n","                                r[\"Type\"],\n","                                r[\"SpeakerId\"]\n","                                ])\n"," \n","    conversation_transcriber.transcribed.connect(handle_final_result) # Connect callbacks to the events fired by the conversation transcriber\n","    conversation_transcriber.session_started.connect(conversation_transcriber_session_started_cb)\n","    conversation_transcriber.session_stopped.connect(conversation_transcriber_session_stopped_cb)\n","    conversation_transcriber.canceled.connect(conversation_transcriber_recognition_canceled_cb)\n","    conversation_transcriber.session_stopped.connect(stop_cb)\n","    conversation_transcriber.canceled.connect(stop_cb)\n","\n","    conversation_transcriber.start_transcribing_async()\n","\n","    # Waits for completion.\n","    while not transcribing_stop:\n","        time.sleep(.5)\n","\n","    conversation_transcriber.stop_transcribing_async()\n","    return(all_results)\n","\n","# try:\n","#     wav_file_path = \"/lakehouse/default/Files/data/audio_input/Travel_20240124183556.wav\"\n","#     r = transcribe_from_file(ai_services_key,ai_services_region,wav_file_path,'f25c4254-1c97-4301-bfaf-d9d20129e67c')\n","#     print(r)\n","# except Exception as err:\n","#     print(\"Encountered exception. {}\".format(err))"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"d029f378-0e5a-41c9-aac6-81abeb63355e","statement_id":13,"statement_ids":[13],"state":"finished","livy_statement_state":"available","queued_time":"2024-05-07T22:02:15.0856142Z","session_start_time":null,"execution_start_time":"2024-05-07T22:02:15.6298682Z","execution_finish_time":"2024-05-07T22:02:15.9068292Z","parent_msg_id":"3212de3a-e8e6-4637-ae3a-00f23f874e43"},"text/plain":"StatementMeta(, d029f378-0e5a-41c9-aac6-81abeb63355e, 13, Finished, Available)"},"metadata":{}}],"execution_count":6,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6e0f17c4-fc8d-4b0d-9ea1-aa72bd640963"},{"cell_type":"code","source":["# # spark.sql('drop table if exists ckm_lakehouse.ckm_conv_messages')\n","\n","# from pyspark.sql import SparkSession\n","\n","# # Create a Spark session\n","# spark = SparkSession.builder.getOrCreate()\n","\n","# # Get the schema of the existing table\n","# schema = spark.table(\"ckm_lakehouse.ckm_conv_messages\").schema\n","\n","# # Create an empty DataFrame with the same schema\n","# empty_df = spark.createDataFrame([], schema)\n","\n","# # Overwrite the existing table with the empty DataFrame\n","# empty_df.write.mode('overwrite').saveAsTable(\"ckm_lakehouse.ckm_conv_messages\")\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c287e232-e8aa-4726-93d5-4d10f45b9b02"},{"cell_type":"code","source":["from pyspark.sql import functions as f\n","\n","for row in df.rdd.collect():\n","    # Strip leading and trailing whitespace from the file name\n","    file_name = row.FileName.strip()\n","    print(file_name)\n","    wav_file_path = '/lakehouse/default/Files/data/audio_input/' + file_name # full path is required for speechSDK\n","    # print(wav_file_path)\n","    try:\n","        r = transcribe_from_file(ai_services_key,ai_services_region,wav_file_path,row.ConversationId)\n","        if len(r) != 0:\n","            df_columns = [\"conversation_id\",\"Id\",\"DisplayText\",\"Offset\",\"Duration\",\"Channel\",\"Type\",\"SpeakerId\"]\n","            df_conv = spark.createDataFrame(data=r, schema = df_columns)\n","            df_conv = df_conv.coalesce(1).withColumn(\"row_id\", f.monotonically_increasing_id())\n","\n","            df_conv.write.format('delta').mode('append').option(\"overwriteSchema\", \"true\").saveAsTable('ckm_conv_messages')\n","                # Move the processed file to the 'audio_processed' folder\n","            print('Files/data/audio_input/' + file_name, 'Files/data/audio_processed/' + file_name)\n","            mssparkutils.fs.mv(('Files/data/audio_input/' + file_name), ('Files/data/audio_processed/' + file_name), False,True)\n","            # break\n","    except Exception as e:\n","        print(\"could not load:\", wav_file_path)\n","        print(\"An error occurred:\", e)  # Print the exception\n","        # Move the processed file to the 'audio_failed' folder\n","        # mssparkutils.fs.mv(('Files/data/audio_input/' + file_name), ('Files/data/audio_failed/' + file_name), False,True)\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d7666408-e048-4cab-beed-dc51ddd1ba86"},{"cell_type":"code","source":["# df = spark.sql(\"SELECT * FROM ckm_lakehouse.`ckm_conv_metadata` LIMIT 1000\")\n","# display(df)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"statement_ids":null,"state":"waiting","livy_statement_state":null,"queued_time":"2024-04-25T17:50:27.9025755Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"210b0909-13a7-4554-8787-1d9dfb1599bd"},"text/plain":"StatementMeta(, , , Waiting, )"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false,"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5c01325f-bf32-4c03-9fcc-ea86657ccbeb"},{"cell_type":"code","source":["import os\n","import shutil\n","\n","# Directory paths\n","input_dir = '/lakehouse/default/Files/data/audio_input/'\n","processed_dir = '/lakehouse/default/Files/data/audio_processed/'\n","\n","# Get a list of all .csv files in the input directory\n","csv_files = [f for f in os.listdir(input_dir) if f.endswith('.csv')]\n","\n","# Move each .csv file to the processed directory\n","for file_name in csv_files:\n","    shutil.move(os.path.join(input_dir, file_name), os.path.join(processed_dir, file_name))\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"d029f378-0e5a-41c9-aac6-81abeb63355e","statement_id":20,"statement_ids":[20],"state":"finished","livy_statement_state":"available","queued_time":"2024-05-07T22:28:10.0263833Z","session_start_time":null,"execution_start_time":"2024-05-07T22:28:10.6882917Z","execution_finish_time":"2024-05-07T22:28:12.2616107Z","parent_msg_id":"dc2b04af-9f53-4c94-a95c-40e4d5621324"},"text/plain":"StatementMeta(, d029f378-0e5a-41c9-aac6-81abeb63355e, 20, Finished, Available)"},"metadata":{}}],"execution_count":13,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3cdf3ba5-0089-4ad5-b6c7-0a38cdcb50ff"},{"cell_type":"code","source":["# df = spark.sql(\"SELECT * FROM ckm_lakehouse.ckm_conv_messages LIMIT 10\")\n","# display(df)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":null,"statement_ids":null,"state":"waiting","livy_statement_state":null,"queued_time":"2024-04-25T17:50:28.5499455Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"648d2074-eb5b-471b-9d34-f77f786ec6cc"},"text/plain":"StatementMeta(, , , Waiting, )"},"metadata":{}}],"execution_count":38,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false,"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"96c0370d-55ea-449c-b19c-ec9fc9a1f6d0"}],"metadata":{"language_info":{"name":"python"},"kernel_info":{"name":"synapse_pyspark"},"microsoft":{"language":"python","ms_spell_check":{"ms_spell_check_language":"en"},"language_group":"synapse_pyspark"},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default"},"dependencies":{"lakehouse":{"default_lakehouse":"e6ad9dad-e3da-4da5-bca6-6572c466b69a","default_lakehouse_name":"ckm_lakehouse","default_lakehouse_workspace_id":"0d98d480-171b-4b4d-a8e7-80fbd031d1a6"},"environment":{"environmentId":"1411cf2c-a611-4a59-b3e0-a88148654974","workspaceId":"f7e840d5-703a-4c30-b473-20646d82a57f"}}},"nbformat":4,"nbformat_minor":5}